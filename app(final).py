import os
from datetime import datetime, timedelta
import json
import hashlib

import pandas as pd
import pydeck as pdk
import streamlit as st
from streamlit_autorefresh import st_autorefresh
from shapely.geometry import shape, Point

# âœ… db.py ê·¸ëŒ€ë¡œ ì‚¬ìš©
from db import init_db, insert_event, fetch_events

# =========================
# Page Config (ì‚¬ì´ë“œë°”ëŠ” ìœ ì§€, ê¸°ë³¸ì€ ì ‘í˜)
# =========================
st.set_page_config(
    page_title="ê³ ë ¹ì ë‚™ìƒ ì˜ˆë°© ê´€ì œ ì‹œìŠ¤í…œ",
    layout="wide",
    initial_sidebar_state="collapsed",
)

ADMDONG_PATH = os.path.join("data", "seoul_admdong.geojson")


TARGET_GU = "ì¢…ë¡œêµ¬"
CCTV_CSV_PATH = os.path.join("data", "seoul_cctv.csv")
JONGNO_BOUNDARY_PATH = os.path.join("data", "jongno_boundary.geojson")

# âœ… ë…¸íŠ¸ë¶(ì›¹ìº ) ê³ ì • ì¢Œí‘œ(ë°ì´í„° ë³´ê°•ìš©)
LAPTOP_LAT = 37.583266
LAPTOP_LON = 126.966548
SOURCE_ID = "laptop_cam_01"

LAPTOP_ROW = {
    "ìì¹˜êµ¬": TARGET_GU,
    "ì•ˆì‹¬ ì£¼ì†Œ": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì˜¥ì¸ë™ 47-264(ë…¸íŠ¸ë¶ ì›¹ìº )",
    "ìœ„ë„": LAPTOP_LAT,
    "ê²½ë„": LAPTOP_LON,
    "CCTV ìˆ˜ëŸ‰": 1,
    "ìˆ˜ì • ì¼ì‹œ": "",
}

# =========================
# Sidebar - Controls (ì™¼ìª½ íŒì—… ê·¸ëŒ€ë¡œ)
# =========================
st.sidebar.header("âš™ï¸ í™”ë©´ ì„¤ì •")

show_environment = st.sidebar.checkbox("í™˜ê²½ ì •ë³´ í‘œì‹œ(ì§€ë„ ì•„ë˜)", value=True)

st.sidebar.divider()
st.sidebar.subheader("ğŸ—ºï¸ CCTV ì  í‘œì‹œ (ì§€ë„=ì¢Œí‘œ í†µí•©)")
show_all_points = st.sidebar.checkbox("ì „ì²´ CCTV ìœ„ì¹˜ í‘œì‹œ", value=False)
show_high_points = st.sidebar.checkbox("High ìœ„ì¹˜ í‘œì‹œ", value=True)
show_medium_points = st.sidebar.checkbox("Medium ìœ„ì¹˜ í‘œì‹œ", value=True)

st.sidebar.divider()
show_event_hex = st.sidebar.checkbox("ì´ë²¤íŠ¸ ê²©ì(HEX) í‘œì‹œ", value=False)

st.sidebar.divider()
time_window = st.sidebar.radio("ëˆ„ì  ê¸°ì¤€", ["ìµœê·¼ 4ì‹œê°„", "ìµœê·¼ 24ì‹œê°„", "ìµœê·¼ 72ì‹œê°„"], index=1)

st.sidebar.divider()
auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ ì‚¬ìš©", value=False)
refresh_minutes = st.sidebar.selectbox("ìƒˆë¡œê³ ì¹¨ ì£¼ê¸°(ë¶„)", [1, 5, 10, 30], index=1)

if st.sidebar.button("ì§€ê¸ˆ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

if auto_refresh:
    st_autorefresh(interval=refresh_minutes * 60 * 1000, key="refresh")

# =========================
# Helpers
# =========================
@st.cache_data
def build_dong_polygons(admdong_jongno_fc: dict):
    """
    return: list of (dong_name, shapely_polygon)
    """
    polys = []
    for f in admdong_jongno_fc.get("features", []):
        props = f.get("properties", {})
        adm_nm = str(props.get("adm_nm", "")).strip()  # "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¬ì§ë™"
        dong = adm_nm.split()[-1] if adm_nm else "ë¯¸ìƒ"
        geom = f.get("geometry")
        if not geom:
            continue
        polys.append((dong, shape(geom)))
    return polys


def assign_dong_nearest(lat: float, lon: float, dong_polys) -> str:
    """
    í´ë¦¬ê³¤ ë‚´ë¶€ë©´ ê·¸ ë™, ì•„ë‹ˆë©´ ê°€ì¥ ê°€ê¹Œìš´ ë™(ê±°ë¦¬ ìµœì†Œ)
    """
    p = Point(lon, lat)

    # 1) contains ìš°ì„ 
    for dong, poly in dong_polys:
        if poly.contains(p):
            return dong

    # 2) ë¯¸ë¶„ë¥˜ -> nearest polygon (boundary distance)
    best_dong = "ë¯¸ë¶„ë¥˜"
    best_dist = float("inf")
    for dong, poly in dong_polys:
        d = poly.distance(p)  # degree ë‹¨ìœ„ì§€ë§Œ "ê°€ê¹Œìš´ ë™ ì„ íƒ"ì—ëŠ” ì¶©ë¶„
        if d < best_dist:
            best_dist = d
            best_dong = dong
    return best_dong

def to_kst(ts: pd.Series) -> pd.Series:
    ts = pd.to_datetime(ts, errors="coerce")
    if getattr(ts.dt, "tz", None) is None:
        ts = ts.dt.tz_localize("UTC")
    return ts.dt.tz_convert("Asia/Seoul")

def filter_admdong_by_gu(geojson_fc: dict, target_gu: str) -> dict:
    kept = []
    for f in geojson_fc.get("features", []):
        props = f.get("properties", {})
        adm_nm = str(props.get("adm_nm", "")).strip()  # âœ… "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¬ì§ë™"
        if target_gu in adm_nm:  # âœ… "ì¢…ë¡œêµ¬" í¬í•¨ì´ë©´ ì¢…ë¡œêµ¬ ë™
            kept.append(f)

    return {
        "type": "FeatureCollection",
        "features": kept,
    }


def layer_dong_outline(geojson_fc: dict):
    return pdk.Layer(
        "GeoJsonLayer",
        data=geojson_fc,
        stroked=True,
        filled=False,
        get_line_color=[80, 80, 80, 90],  # ì—°íšŒìƒ‰ + íˆ¬ëª…
        get_line_width=1,
        line_width_min_pixels=1,
        line_width_max_pixels=2,
        pickable=False,
    )

def _flatten_coords(coords):
    """
    Polygon/MultiPolygon ì¢Œí‘œë¥¼ ì¬ê·€ì ìœ¼ë¡œ í¼ì³ì„œ (lon, lat) ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    pts = []

    def walk(c):
        if isinstance(c, (list, tuple)) and len(c) == 2 and isinstance(c[0], (int, float)):
            lon, lat = c
            pts.append((lon, lat))
        else:
            for x in c:
                walk(x)

    walk(coords)
    return pts

def make_dong_label_points(admdong_fc: dict) -> pd.DataFrame:
    rows = []
    for f in admdong_fc.get("features", []):
        props = f.get("properties", {})
        name = str(props.get("adm_nm", "")).strip()  # "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¬ì§ë™"

        geom = f.get("geometry", {})
        coords = geom.get("coordinates", [])

        pts = _flatten_coords(coords)
        if not pts:
            continue

        lon_avg = sum(p[0] for p in pts) / len(pts)
        lat_avg = sum(p[1] for p in pts) / len(pts)

        short = name.split()[-1] if name else ""
        rows.append({"adm_nm": name, "dong": short, "lon": lon_avg, "lat": lat_avg})

    return pd.DataFrame(rows)


def layer_dong_labels(df_labels: pd.DataFrame):
    if df_labels is None or df_labels.empty:
        return None

    df = df_labels.copy()

    # âœ… label ì»¬ëŸ¼ ê°•ì œ ìƒì„± (dongê°€ ì—†ìœ¼ë©´ adm_nm ë§ˆì§€ë§‰ ë‹¨ì–´ë¡œë¼ë„)
    if "dong" in df.columns:
        df["label"] = df["dong"].astype(str)
    elif "adm_nm" in df.columns:
        df["label"] = df["adm_nm"].astype(str).apply(lambda x: str(x).split()[-1])
    else:
        return None

    # âœ… ì¢Œí‘œ íƒ€ì… ë³´ì •
    df["lon"] = pd.to_numeric(df["lon"], errors="coerce")
    df["lat"] = pd.to_numeric(df["lat"], errors="coerce")
    df = df.dropna(subset=["lon", "lat", "label"])
    if df.empty:
        return None

    return pdk.Layer(
        "TextLayer",
        data=df,
        get_position="[lon, lat]",
        get_text="label",
        get_size=16,
        size_units="pixels",
        size_min_pixels=12,
        size_max_pixels=28,
        billboard=True,              # âœ… ì¹´ë©”ë¼ íšŒì „ì— ìƒê´€ì—†ì´ ì •ë©´ í‘œì‹œ
        get_color=[20, 20, 20, 230],
        pickable=False,
    )




def make_last_4hour_bins_kst():
    now_kst = pd.Timestamp.now(tz="Asia/Seoul").floor("H")
    hours_kst = [now_kst - pd.Timedelta(hours=i) for i in range(3, -1, -1)]
    idx_kst = pd.DatetimeIndex(hours_kst)

    labels = [
        f"{h.strftime('%H:%M')}~{(h + pd.Timedelta(hours=1)).strftime('%H:%M')}"
        for h in idx_kst
    ]
    return idx_kst, labels


def get_window_hours() -> int:
    return {"ìµœê·¼ 4ì‹œê°„": 4, "ìµœê·¼ 24ì‹œê°„": 24, "ìµœê·¼ 72ì‹œê°„": 72}[time_window]


def safe_read_csv(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path, encoding="euc-kr")
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="utf-8")


@st.cache_data
def load_boundary_geojson(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def _iter_coords(coords):
    # Polygon/MultiPolygon ì¢Œí‘œë¥¼ ì „ë¶€ ìˆœíšŒí•˜ë©´ì„œ (lon, lat) ë½‘ê¸°
    if isinstance(coords, (list, tuple)) and coords and isinstance(coords[0], (int, float)):
        yield coords  # [lon, lat]
    else:
        for c in coords:
            yield from _iter_coords(c)

def geojson_centroid_lonlat(geom: dict):
    # ì •í™•í•œ ì¤‘ì‹¬(ì§€ì˜¤ë©”íŠ¸ë¦¬ ì¤‘ì‹¬ì ) ê³„ì‚°ì€ shapelyê°€ í•„ìš”í•˜ì§€ë§Œ,
    # ì—¬ê¸°ì„  "ë¼ë²¨ ìœ„ì¹˜ìš©"ìœ¼ë¡œ bbox ì¤‘ì‹¬ì„ ì‚¬ìš© (ì¶©ë¶„íˆ ë³´ê¸° ì¢‹ìŒ)
    coords = list(_iter_coords(geom.get("coordinates", [])))
    if not coords:
        return None, None
    lons = [c[0] for c in coords]
    lats = [c[1] for c in coords]
    return (min(lons) + max(lons)) / 2, (min(lats) + max(lats)) / 2

@st.cache_data
def build_dong_label_df(seoul_dong_geojson_path: str, target_gu: str) -> pd.DataFrame:
    with open(seoul_dong_geojson_path, "r", encoding="utf-8") as f:
        fc = json.load(f)

    rows = []
    for feat in fc.get("features", []):
        props = feat.get("properties", {})
        adm_nm = str(props.get("adm_nm", ""))  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¬ì§ë™"
        key = f" {target_gu} "
        if key not in adm_nm:
            continue

        # ë™ ì´ë¦„ë§Œ ë½‘ê¸°: "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¬ì§ë™" -> "ì‚¬ì§ë™"
        dong_name = adm_nm.split()[-1]

        lon, lat = geojson_centroid_lonlat(feat.get("geometry", {}))
        if lon is None:
            continue

        rows.append({"dong": dong_name, "lon": lon, "lat": lat})

    return pd.DataFrame(rows)


def layer_gu_outline(geojson_fc: dict):
    return pdk.Layer(
        "GeoJsonLayer",
        data=geojson_fc,
        stroked=True,
        filled=False,
        get_line_color=[0, 120, 255, 110],
        get_line_width=2,
        line_width_min_pixels=1,
        line_width_max_pixels=3,
        pickable=False,
    )


def make_camera_id(address: str, lat: float, lon: float) -> str:
    s = f"{address}|{lat:.6f}|{lon:.6f}".encode("utf-8")
    h = hashlib.sha1(s).hexdigest()[:10]
    return f"CAM_{h}"


@st.cache_data
def load_cctv_data():
    """
    cameras_df: ì£¼ì†Œ ë‹¨ìœ„(ì¤‘ë³µ ì¢Œí‘œ í—ˆìš©)
    sites_df: ì¢Œí‘œ ë‹¨ìœ„(ì§€ë„ìš© í†µí•©)
    """
    if not os.path.exists(CCTV_CSV_PATH):
        raise FileNotFoundError(
            f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CCTV_CSV_PATH}\n"
            f"project_1/data/seoul_cctv.csv ê²½ë¡œë¡œ ë„£ì–´ì£¼ì„¸ìš”."
        )

    df = safe_read_csv(CCTV_CSV_PATH)

    required = ["ìì¹˜êµ¬", "ì•ˆì‹¬ ì£¼ì†Œ", "ìœ„ë„", "ê²½ë„", "CCTV ìˆ˜ëŸ‰", "ìˆ˜ì • ì¼ì‹œ"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"CSV ì»¬ëŸ¼ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ëˆ„ë½: {missing}\ní˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")

    df = df[df["ìì¹˜êµ¬"] == TARGET_GU].copy()

    df["ìœ„ë„"] = pd.to_numeric(df["ìœ„ë„"], errors="coerce")
    df["ê²½ë„"] = pd.to_numeric(df["ê²½ë„"], errors="coerce")
    df["CCTV ìˆ˜ëŸ‰"] = pd.to_numeric(df["CCTV ìˆ˜ëŸ‰"], errors="coerce").fillna(1).astype(int)
    df = df.dropna(subset=["ìœ„ë„", "ê²½ë„", "ì•ˆì‹¬ ì£¼ì†Œ"]).copy()

    # ë…¸íŠ¸ë¶(ì›¹ìº ) ì¶”ê°€
    df = pd.concat([df, pd.DataFrame([LAPTOP_ROW])], ignore_index=True)

    cameras = df.copy()
    cameras["lat"] = cameras["ìœ„ë„"].astype(float)
    cameras["lon"] = cameras["ê²½ë„"].astype(float)
    cameras["camera_id"] = cameras.apply(
        lambda r: make_camera_id(str(r["ì•ˆì‹¬ ì£¼ì†Œ"]), float(r["lat"]), float(r["lon"])),
        axis=1
    )
    cameras = cameras.drop_duplicates(subset=["camera_id"]).reset_index(drop=True)

    sites = (
        cameras.groupby(["lat", "lon"], as_index=False)
        .agg({"ìì¹˜êµ¬": "first", "CCTV ìˆ˜ëŸ‰": "sum", "ì•ˆì‹¬ ì£¼ì†Œ": "count"})
        .rename(columns={"ì•ˆì‹¬ ì£¼ì†Œ": "ì¹´ë©”ë¼ ìˆ˜"})
        .copy()
    )
    sites["site_id"] = "SITE_" + sites.index.astype(str).str.zfill(5)

    cameras = cameras.merge(sites[["lat", "lon", "site_id"]], on=["lat", "lon"], how="left")
    return cameras, sites


def load_events_df(limit: int = 8000) -> pd.DataFrame:
    rows = fetch_events(limit=limit)
    if not rows:
        return pd.DataFrame(columns=["ts", "lat", "lon", "dong", "cctv_id", "event_type", "confidence", "source_id"])

    df = pd.DataFrame(rows, columns=["ts", "lat", "lon", "dong", "cctv_id", "event_type", "confidence", "source_id"])
    df["ts"] = pd.to_datetime(df["ts"], errors="coerce")
    df["lat"] = pd.to_numeric(df["lat"], errors="coerce")
    df["lon"] = pd.to_numeric(df["lon"], errors="coerce")
    df = df.dropna(subset=["ts", "lat", "lon", "cctv_id"]).copy()
    return df


def filter_events_by_time(df: pd.DataFrame) -> pd.DataFrame:
    cutoff = datetime.utcnow() - timedelta(hours=get_window_hours())
    return df[df["ts"] >= pd.Timestamp(cutoff)].copy()


def priority_from_count(n: int) -> str:
    if n >= 3:
        return "High"
    elif n >= 1:
        return "Medium"
    return "Low"


def scatter_layer(df: pd.DataFrame, radius: int, color_rgba: list):
    return pdk.Layer(
        "ScatterplotLayer",
        data=df,
        get_position="[lon, lat]",
        get_radius=radius,
        get_fill_color=color_rgba,
        pickable=True,
    )


def layer_event_hex(df_events: pd.DataFrame):
    if df_events.empty:
        return None
    return pdk.Layer(
        "HexagonLayer",
        data=df_events,
        get_position="[lon, lat]",
        radius=35,
        elevation_scale=0,
        extruded=False,
        pickable=True,
    )
    
def point_in_polygon(lon: float, lat: float, ring: list) -> bool:
    """
    ring: [[lon,lat], [lon,lat], ...]  (Polygonì˜ ë°”ê¹¥ìª½ ë§ 1ê°œ)
    Ray casting ì•Œê³ ë¦¬ì¦˜
    """
    inside = False
    n = len(ring)
    if n < 3:
        return False

    x, y = lon, lat
    x0, y0 = ring[0]
    for i in range(1, n + 1):
        x1, y1 = ring[i % n]
        # yê°€ ì„ ë¶„ ì‚¬ì´ì— ìˆê³ , êµì°¨ ì—¬ë¶€ ê³„ì‚°
        if ((y0 > y) != (y1 > y)):
            x_intersect = (x1 - x0) * (y - y0) / (y1 - y0 + 1e-12) + x0
            if x < x_intersect:
                inside = not inside
        x0, y0 = x1, y1

    return inside


def point_in_geom(lon: float, lat: float, geom: dict) -> bool:
    """
    GeoJSON geometry(Polygon/MultiPolygon) ë‚´ë¶€ ì—¬ë¶€
    - ë°”ê¹¥ ë§ë§Œ ì‚¬ìš©(holes ë¬´ì‹œ): í–‰ì •ë™ ê²½ê³„ëŠ” ë³´í†µ holes ê±°ì˜ ì—†ì–´ì„œ ì‹¤ë¬´ì ìœ¼ë¡œ OK
    """
    gtype = geom.get("type")
    coords = geom.get("coordinates", [])

    if gtype == "Polygon":
        # coords = [outer_ring, hole1, ...]
        outer = coords[0] if coords else []
        return point_in_polygon(lon, lat, outer)

    if gtype == "MultiPolygon":
        # coords = [ [poly1], [poly2], ... ] where poly = [outer, holes...]
        for poly in coords:
            outer = poly[0] if poly else []
            if point_in_polygon(lon, lat, outer):
                return True
        return False

    return False


def assign_dong_to_points(df_points: pd.DataFrame, admdong_fc: dict, lon_col="lon", lat_col="lat") -> pd.DataFrame:
    """
    df_pointsì˜ ê° ì ì— ëŒ€í•´ ë™(adm_nm / dong)ì„ ë§¤ì¹­
    """
    features = admdong_fc.get("features", [])

    def find_dong(row):
        lon = float(row[lon_col])
        lat = float(row[lat_col])

        for f in features:
            props = f.get("properties", {})
            name = str(props.get("adm_nm", "")).strip()
            geom = f.get("geometry", {})
            if point_in_geom(lon, lat, geom):
                short = name.split()[-1] if name else ""
                return short
        return "ë¯¸ë¶„ë¥˜"

    out = df_points.copy()
    out["dong"] = out.apply(find_dong, axis=1)
    return out



def render_environment_info_below_map():
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸŒ¡ í˜„ì¬ ê¸°ì˜¨", "-3.2Â°C")
    with col2:
        st.metric("â° í˜„ì¬ ì‹œê°", datetime.now().strftime("%H:%M"))
    with col3:
        st.metric("ğŸŒ¨ ìµœê·¼ 24ì‹œê°„ ê°•ì„¤ëŸ‰", "6.5 cm")


def render_map(sites_all, sites_medium, sites_high, df_recent_events):
    boundary_gu = load_boundary_geojson(JONGNO_BOUNDARY_PATH)

    admdong_all = load_boundary_geojson(ADMDONG_PATH)
    admdong_jongno = filter_admdong_by_gu(admdong_all, TARGET_GU)

    layers = [
        layer_gu_outline(boundary_gu),         # âœ… ì¢…ë¡œêµ¬ êµ¬ ê²½ê³„
        layer_dong_outline(admdong_jongno),    # âœ… ì¢…ë¡œêµ¬ ë™ ê²½ê³„(ì–‡ê²Œ)
    ]

    if show_event_hex:
        hex_layer = layer_event_hex(df_recent_events)
        if hex_layer:
            layers.append(hex_layer)

    if show_all_points:
        layers.append(scatter_layer(sites_all, radius=12, color_rgba=[60, 60, 60, 80]))
    if show_medium_points:
        layers.append(scatter_layer(sites_medium, radius=18, color_rgba=[255, 200, 0, 220]))
    if show_high_points:
        layers.append(scatter_layer(sites_high, radius=22, color_rgba=[255, 0, 0, 230]))

    deck = pdk.Deck(
        map_style=None,
        initial_view_state=pdk.ViewState(
            latitude=37.572,
            longitude=126.98,
            zoom=12.9,
            pitch=0,
        ),
        layers=layers,
        tooltip={"text": "SITE: {site_id}\nìš°ì„ ë„: {priority}\nì´ë²¤íŠ¸: {event_count}\nì¹´ë©”ë¼ ìˆ˜: {ì¹´ë©”ë¼ ìˆ˜}"},
    )
    st.pydeck_chart(deck, use_container_width=True, height=860)


def build_site_hour_table(site_events: pd.DataFrame, site_cams: pd.DataFrame):
    """
    ì„ íƒ SITEì˜ CCTV ëª©ë¡ì— 'ìµœê·¼ 4ì‹œê°„(ì‹œê°„ì¹¸ 4ê°œ + ì¶”ì´)' ë¶™ì—¬ì„œ ë°˜í™˜
    - site_cams: cameras_dfì˜ site_id í•„í„° ê²°ê³¼
    - site_events: events_with_siteì—ì„œ site_id í•„í„° ê²°ê³¼
    """
    idx_kst, hour_labels = make_last_4hour_bins_kst()
    pivot = pd.DataFrame(0, index=site_cams["camera_id"], columns=hour_labels)

    if not site_events.empty:
        site_events = site_events.copy()
        site_events["ts_kst"] = to_kst(site_events["ts"])
        site_events["hour_kst"] = site_events["ts_kst"].dt.floor("H")

        cam_hour = (
            site_events.groupby(["camera_id", "hour_kst"])
            .size()
            .reset_index(name="cnt")
        )

        tmp = cam_hour.pivot(index="camera_id", columns="hour_kst", values="cnt").fillna(0).astype(int)
        tmp = tmp.reindex(columns=idx_kst, fill_value=0)
        tmp.columns = hour_labels
        pivot.update(tmp)

    out = site_cams.merge(pivot, left_on="camera_id", right_index=True, how="left")
    out[hour_labels] = out[hour_labels].fillna(0).astype(int)

    def fmt_with_trend(curr: int, prev: int) -> str:
        d = curr - prev
        if d > 0:
            return f"{curr}(ğŸ”º{d})"
        elif d < 0:
            return f"{curr}(ğŸ”»{abs(d)})"
        else:
            return f"{curr}(â–¬0)"

    # ì›ë³¸ ë³´ê´€
    for col in hour_labels:
        out[col + "_n"] = out[col].astype(int)

    for i, col in enumerate(hour_labels):
        if i == 0:
            out[col] = out[col + "_n"].apply(lambda v: f"{v}(â–¬0)")
        else:
            prev_col = hour_labels[i - 1]
            out[col] = out.apply(lambda r: fmt_with_trend(int(r[col + "_n"]), int(r[prev_col + "_n"])), axis=1)

    return out, hour_labels


# =========================
# Init + Load
# =========================
init_db()

st.title(f"â„ï¸ {TARGET_GU} ê³ ë ¹ì ë‚™ìƒ ì˜ˆë°© ê´€ì œ ì‹œìŠ¤í…œ")
st.caption("ì§€ë„=ì¢Œí‘œ í†µí•©(SITE) Â· ìš´ì˜/ì¶”ì =ì•ˆì‹¬ì£¼ì†Œ(CAMERA)")

cameras_df, sites_df = load_cctv_data()

df_events_all = load_events_df(limit=8000)
df_recent = filter_events_by_time(df_events_all)

# =========================
# ë™ ê²½ê³„(ì¢…ë¡œêµ¬) ë¡œë“œ (ì§‘ê³„/ë¼ë²¨ ê³µìš©)
# =========================
ADMDONG_PATH = os.path.join("data", "seoul_admdong.geojson")

admdong_all = load_boundary_geojson(ADMDONG_PATH)
admdong_jongno = filter_admdong_by_gu(admdong_all, TARGET_GU)


# ì´ë²¤íŠ¸ëŠ” camera_id(ì£¼ì†Œ ë‹¨ìœ„)ë§Œ ì¸ì •
camera_ids = set(cameras_df["camera_id"].tolist())
if not df_recent.empty:
    df_recent = df_recent[df_recent["cctv_id"].isin(camera_ids)].copy()

# Camera ìš°ì„ ë„/ì¹´ìš´íŠ¸
cam_counts = df_recent.groupby("cctv_id").size().to_dict() if not df_recent.empty else {}
cameras_df["event_count"] = cameras_df["camera_id"].map(lambda x: int(cam_counts.get(x, 0)))
cameras_df["priority"] = cameras_df["event_count"].map(priority_from_count)

# Site ìš°ì„ ë„/ì¹´ìš´íŠ¸
events_joined = df_recent.merge(
    cameras_df[["camera_id", "site_id"]],
    left_on="cctv_id",
    right_on="camera_id",
    how="left"
)
site_counts = events_joined.groupby("site_id").size().to_dict() if not events_joined.empty else {}
sites_df["event_count"] = sites_df["site_id"].map(lambda x: int(site_counts.get(x, 0)))
sites_df["priority"] = sites_df["event_count"].map(priority_from_count)
# =========================
# SITE(ì¢Œí‘œ í†µí•©)ì— ë™(dong) ë§¤í•‘
# =========================
sites_df = assign_dong_to_points(
    sites_df,
    admdong_jongno,
    lon_col="lon",
    lat_col="lat"
)
# âœ… ì¢…ë¡œêµ¬ ë™ í´ë¦¬ê³¤ ì¤€ë¹„
admdong_all = load_boundary_geojson(ADMDONG_PATH)
admdong_jongno = filter_admdong_by_gu(admdong_all, TARGET_GU)
dong_polys = build_dong_polygons(admdong_jongno)

# âœ… sites_dfì— dong í• ë‹¹ (ë¯¸ë¶„ë¥˜ë„ nearestë¡œ ê·€ì†)
sites_df["dong"] = sites_df.apply(lambda r: assign_dong_nearest(r["lat"], r["lon"], dong_polys), axis=1)

sites_high = sites_df[sites_df["priority"] == "High"].copy()
sites_medium = sites_df[sites_df["priority"] == "Medium"].copy()
sites_all = sites_df.copy()

# =========================
# Layout (ì¢Œ:ì§€ë„ / ìš°:ìš”ì•½+ê·¸ë˜í”„+ìˆœìœ„+ì„ íƒ ìƒì„¸)
# =========================
left, right = st.columns([5, 5], gap="large")

with left:
    st.subheader("ğŸ—ºï¸ ìœ„í—˜ í˜„í™© ì§€ë„ (High/Medium ì¤‘ì‹¬)")
    render_map(sites_all, sites_medium, sites_high, df_recent)

    # âœ… í™˜ê²½ì •ë³´ëŠ” ì§€ë„ ì•„ë˜ë¡œ
    if show_environment:
        st.divider()
        render_environment_info_below_map()

    st.caption(
        f"ëˆ„ì  ê¸°ì¤€: {time_window} Â· "
        f"ìƒˆë¡œê³ ì¹¨: {'OFF' if not auto_refresh else str(refresh_minutes) + 'ë¶„'} Â· "
        f"í‘œì‹œ: "
        f"{'ì „ì²´ ' if show_all_points else ''}"
        f"{'Medium ' if show_medium_points else ''}"
        f"{'High ' if show_high_points else ''}"
        f"{'(HEX ON)' if show_event_hex else ''}"
    )

with right:
    st.subheader("ğŸ” ìƒí™© ìš”ì•½")
    high_cnt = int((sites_df["priority"] == "High").sum())
    med_cnt = int((sites_df["priority"] == "Medium").sum())
    total_recent = int(len(df_recent))

    k1, k2, k3,k4 = st.columns(4)
    with k1:
        st.metric("ğŸ”´ High (SITE)", f"{high_cnt:,}")
    with k2:
        st.metric("ğŸŸ  Medium (SITE)", f"{med_cnt:,}")
    with k3:
        st.metric("ìµœê·¼ ì´ë²¤íŠ¸", f"{total_recent:,}")
    with k4:
        st.metric("High ì¢Œí‘œ ìˆ˜", f"{len(sites_high):,}")
    dong_site_stats = (
    sites_df[sites_df["priority"].isin(["High", "Medium"])]
    .groupby(["dong", "priority"])
    .size()
    .unstack(fill_value=0)
    .reset_index()
)

    if "High" not in dong_site_stats.columns:
        dong_site_stats["High"] = 0
    if "Medium" not in dong_site_stats.columns:
        dong_site_stats["Medium"] = 0

    dong_site_stats["High+Medium"] = dong_site_stats["High"] + dong_site_stats["Medium"]
    dong_site_stats = dong_site_stats.sort_values(
        ["High", "Medium"], ascending=[False, False]
    )

    st.subheader("ğŸ˜ï¸ ë™ë³„ ìœ„í—˜ ì¢Œí‘œ(SITE) í˜„í™©")
    st.dataframe(dong_site_stats, use_container_width=True)
    # ---- ìš°ì¸¡ ì¤‘ë‹¨: High/Medium ì¶”ì´ ----
    st.markdown("### ğŸ“ˆ High/Medium ì¶”ì´ (ìµœê·¼ 4ì‹œê°„)")
    # site-hour ê¸°ì¤€ìœ¼ë¡œ High/Medium ì§‘ê³„ (ë‹¨ìˆœ but ê´€ì œìš© ì¶©ë¶„)
    idx_kst, hour_labels = make_last_4hour_bins_kst()
    trend = pd.DataFrame({"High": [0]*4, "Medium": [0]*4}, index=hour_labels)

    if not df_recent.empty:
        tmp = df_recent.merge(
            cameras_df[["camera_id", "site_id"]],
            left_on="cctv_id",
            right_on="camera_id",
            how="left"
        ).dropna(subset=["site_id"]).copy()
        if not tmp.empty:
            tmp["ts_kst"] = to_kst(tmp["ts"])
            tmp["hour_kst"] = tmp["ts_kst"].dt.floor("H")
            tmp = tmp[tmp["hour_kst"].isin(idx_kst)].copy()

            if not tmp.empty:
                site_hour = tmp.groupby(["site_id", "hour_kst"]).size().reset_index(name="cnt")
                site_hour["priority"] = site_hour["cnt"].map(priority_from_count)

                for i, h in enumerate(idx_kst):
                    one = site_hour[site_hour["hour_kst"] == h]
                    trend.loc[hour_labels[i], "High"] = int(one.loc[one["priority"] == "High", "cnt"].sum())
                    trend.loc[hour_labels[i], "Medium"] = int(one.loc[one["priority"] == "Medium", "cnt"].sum())

    st.line_chart(trend, height=220)

    # ---- ìš°ì¸¡ í•˜ë‹¨: ìœ„í—˜ë„ ìˆœìœ„ + í´ë¦­(ì„ íƒ) ìƒì„¸ ----
    st.markdown("### âš ï¸ ìœ„í—˜ë„ ìˆœìœ„ (ì¡°ì¹˜ ìš°ì„ , High/Medium SITE)")
    risk_sites = sites_df[sites_df["priority"].isin(["High", "Medium"])].copy()

    if risk_sites.empty:
        st.info("í˜„ì¬ ì‹œê°„ì°½ ê¸°ì¤€ìœ¼ë¡œ High/Medium ìœ„í—˜ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        selected_site_id = None
    else:
        # High ë¨¼ì € ë‚˜ì˜¤ê²Œ ì •ë ¬ ê°•ì œ
        order_map = {"High": 0, "Medium": 1, "Low": 2}
        risk_sites["p_rank"] = risk_sites["priority"].map(order_map).fillna(9).astype(int)
        risk_sites = risk_sites.sort_values(["p_rank", "event_count"], ascending=[True, False]).drop(columns=["p_rank"])

        # âœ… "ìˆœìœ„í‘œ" + "ì„ íƒ" UX
        rank_view = risk_sites[["site_id", "priority", "event_count", "ì¹´ë©”ë¼ ìˆ˜"]].copy()
        rank_view = rank_view.rename(columns={"event_count": "ìµœê·¼ ì´ë²¤íŠ¸", "ì¹´ë©”ë¼ ìˆ˜": "ì¹´ë©”ë¼(ì£¼ì†Œ) ìˆ˜"})
        rank_view = rank_view.reset_index(drop=True)
        rank_view.index = rank_view.index + 1
        st.dataframe(rank_view.head(25), use_container_width=True, height=260)

        # ì„ íƒ ì»¨íŠ¸ë¡¤ (table clickì€ streamlit ê¸°ë³¸ìœ¼ë¡œ ëª» ë°›ìœ¼ë‹ˆ selectboxë¡œ)
        risk_sites["label"] = risk_sites.apply(
            lambda r: f"{r['site_id']} | {r['priority']} | ì´ë²¤íŠ¸ {int(r['event_count'])} | ì¹´ë©”ë¼ {int(r['ì¹´ë©”ë¼ ìˆ˜'])}ëŒ€",
            axis=1
        )
        selected_label = st.selectbox("ìƒì„¸ë¡œ ë³¼ ìœ„í—˜ ì§€ì—­(SITE) ì„ íƒ", options=risk_sites["label"].tolist(), index=0)
        selected_site_id = risk_sites.loc[risk_sites["label"] == selected_label, "site_id"].values[0]

    # =========================
    # âœ… ë‹¤ìŒ ë‹¨ê³„: ì„ íƒ SITE ìƒì„¸ (CCTV ëª©ë¡+ì‹œê°„ì¹¸+ì¶”ì´+ë¡œê·¸)
    # =========================
    if selected_site_id is not None:
        st.divider()
        st.subheader("ğŸ“ ì„ íƒ ìœ„í—˜ ì§€ì—­ ìƒì„¸ (SITE â†’ CCTV ëª©ë¡/ë¡œê·¸)")

        # í•´ë‹¹ SITEì˜ ì¹´ë©”ë¼ ëª©ë¡(ì£¼ì†Œ ë‹¨ìœ„)
        site_cams = cameras_df[cameras_df["site_id"] == selected_site_id].copy()
        site_cams = site_cams.sort_values(["event_count"], ascending=False).reset_index(drop=True)

        # ì´ë²¤íŠ¸ì— site ë¶™ì´ê³  ì„ íƒ siteë§Œ
        events_with_site = df_recent.merge(
            cameras_df[["camera_id", "site_id"]],
            left_on="cctv_id",
            right_on="camera_id",
            how="left"
        )
        site_events = events_with_site[events_with_site["site_id"] == selected_site_id].copy()

        # ì‹œê°„ì¹¸ 4ê°œ + ì¶”ì´ ë¶™ì¸ í‘œ
        site_table, hour_cols = build_site_hour_table(site_events=site_events, site_cams=site_cams)

        st.markdown("#### ğŸ“‹ í•´ë‹¹ ì§€ì—­ CCTV ëª©ë¡ (ì‹œê°„ëŒ€ë³„ 4ì¹¸ + ì¶”ì´)")
        show_cols = ["camera_id", "ì•ˆì‹¬ ì£¼ì†Œ", "priority", "event_count"] + hour_cols
        st.dataframe(site_table[show_cols], use_container_width=True, height=260)

        # ë¡œê·¸ ë³¼ CCTV ì„ íƒ
        cams_with_recent = site_table[site_table["event_count"] > 0]
        cams_for_select = cams_with_recent if not cams_with_recent.empty else site_table

        selected_cam_in_site = st.selectbox(
            "ì´ ì§€ì—­ì—ì„œ ë¡œê·¸ ë³¼ CCTV ì„ íƒ",
            options=cams_for_select["camera_id"].tolist(),
            index=0,
            format_func=lambda cid: (
                f"{cams_for_select.loc[cams_for_select['camera_id']==cid,'ì•ˆì‹¬ ì£¼ì†Œ'].values[0]} "
                f"(ì´ë²¤íŠ¸ {int(cams_for_select.loc[cams_for_select['camera_id']==cid,'event_count'].values[0])})"
            )
        )

        st.markdown("#### ğŸ§¾ ì„ íƒ CCTV ì´ë²¤íŠ¸ ë¡œê·¸ (KST)")
        sel_events_site = df_recent[df_recent["cctv_id"] == selected_cam_in_site].copy()

        if sel_events_site.empty:
            st.info("í•´ë‹¹ CCTVì— ìµœê·¼ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sel_events_site = sel_events_site.sort_values("ts", ascending=False)
            sel_events_site["ts_kst"] = to_kst(sel_events_site["ts"]).dt.strftime("%Y-%m-%d %H:%M:%S")
            st.dataframe(
                sel_events_site[["ts_kst", "event_type", "confidence", "source_id"]].head(150),
                use_container_width=True,
                height=260
            )

# =========================
# âœ… í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸ëŠ” "ë§¨ ì•„ë˜"ë¡œ ì´ë™
# =========================
st.divider()
st.subheader("ğŸ§ª í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸ ìƒì„± (ë§¨ ì•„ë˜)")
st.caption("ëª¨ë¸ ì—°ë™ ì „/í›„, ì´ë²¤íŠ¸ â†’ DB â†’ ì§€ë„/ì§‘ê³„ íë¦„ë§Œ í™•ì¸í•˜ëŠ” ìš©ë„ì…ë‹ˆë‹¤.")

selected_camera_id = st.selectbox(
    "CCTV ì„ íƒ(ì•ˆì‹¬ì£¼ì†Œ ê¸°ì¤€)",
    options=cameras_df["camera_id"].tolist(),
    index=0,
    format_func=lambda cid: f"{cameras_df.loc[cameras_df['camera_id']==cid,'ì•ˆì‹¬ ì£¼ì†Œ'].values[0]}",
)
selected_cam_row = cameras_df[cameras_df["camera_id"] == selected_camera_id].iloc[0]

if st.button("ì„ íƒ CCTVì— ë‚™ìƒ ì´ë²¤íŠ¸ ì €ì¥(í…ŒìŠ¤íŠ¸)"):
    insert_event(
        lat=float(selected_cam_row["lat"]),
        lon=float(selected_cam_row["lon"]),
        dong=TARGET_GU,
        cctv_id=selected_camera_id,
        event_type="fall",
        confidence=0.9,
        source_id=SOURCE_ID,
    )
    st.success("ì´ë²¤íŠ¸ ì €ì¥ ì™„ë£Œ")
    st.rerun()

st.divider()
st.info(
    f"""
    ë³¸ ì‹œìŠ¤í…œì€ **{TARGET_GU} CCTV ì¢Œí‘œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ**,  
    ì§€ë„ëŠ” **ì¢Œí‘œ í†µí•©(SITE)** ìœ¼ë¡œ ìœ„í—˜ ì§€ì—­ì„ í•œëˆˆì— ë³´ì—¬ì£¼ê³ ,  
    ìš´ì˜/ì¶”ì ì€ **ì•ˆì‹¬ì£¼ì†Œ(CAMERA) ë‹¨ìœ„**ë¡œ ë¶„ë¦¬í•˜ì—¬  
    ë™ì¼ ìœ„ì¹˜ì˜ ì—¬ëŸ¬ CCTV ì¤‘ **ì–´ëŠ CCTVì—ì„œ ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆëŠ”ì§€** ì¶”ì  ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
    """
)
